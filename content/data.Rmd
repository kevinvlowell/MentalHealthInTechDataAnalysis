---
title: Data
description:
toc: true
featuredVideo:
featuredImage: images/Charlotte-Edey-phones.jpg
# images/data-import-cheatsheet-thumbs.png
draft: false
---

This comes from the file `content/data.Rmd`.

Your first steps in this project will be to find data to work on.

I recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.

You are __not__ allowed to work on COVID data.

Initially, you will find _one dataset_ but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable.
Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components.

### Sharing your data

My recommendation for sharing the data is to not track it on Github unless the data is relatively small <2-3mb. 

For small datasets, you can use the `dataset` folder that is tracked by github. Add the files just like you would any other file.

For larger datasets, you'll need to create a new folder in the project root directory called `dataset-ignore`. This will be ignored by git which will help you avoid issues with Github's size limits. Your team will have to manually make sure the data files in `dataset-ignore` are synced across team members.

Your [load_and_clean_data.R](/load_and_clean_data.R) file is how you will load your data. Here is a an example of a very simple one.

```{r}
source(
  here::here("static", "load_and_clean_data.R"),
  echo = TRUE # Use echo=FALSE or omit it to avoid code output  
)
```

Note how I use the `here::here` function to avoid path problems.

----

### Introduction: Who, What, Where, When, and Why?
* Describe where/how to find data.
  * You must include a link to the original data source(s).
  
Our data comes from [OSMI's Mental Health in Tech Survey](https://osmihelp.org/research). To access the 2016 and 2018 datasets that were used in our analyses, scroll down the linked page and click "Get raw data" for each year.

Open Sourcing Mental Illness (OSMI) is a "non-profit dedicated to raising awareness, educating, and providing resources to support wellness in the tech and open source communities." The non-profit has been conducting annual surveys on mental health in tech since 2014, with the goal of raising awareness and educating others about mental wellness in tech communities. Comprised of volunteers and mental health experts passionate about mental well-being, OSMI strives to positively change the experiences of those with mental health disorders in the workplace, especially through leveraging the power of continuous data collection. To collect the data sets being analyzed, OSMI hosts annual online research surveys that ask participants a range of questions regarding attitudes towards mental health, the prevalence of mental health disorders, workplace encounters related to mental health, and much more. Participation in the survey is promoted throughout the year via outreach at conferences, companies, and relevant communities.

To learn more about their mission and inspiring initiatives, visit https://osmihelp.org/about.
  
### Our Data Files

* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
  
For our analyses, we used the data files from OSMI's 2016 and 2018 Mental Health in Tech surveys. The 2016 data set served as our primary set for analysis, and the 2018 dataset was subsequently loaded and groomed to allow the set to be appropriately joined with the 2016 data in order to facilitate chronological comparisons. In total, the original 2016 data file consisted of 63 questions and 1433 survey responses, and the original 2018 data file consisted of 123 questions and 417 survey responses.

To summarize, each of the variables within each data set represented one of the questions asked in OSMI's surveys, with each year's survey containing some new additions, deletions, and edits to the question bank. With each row representing an individual survey submission, the values under each of the column variables represent the survey participant's response to the corresponding question. In addition, one of the more important aspects of the variables was that the questions roughly fell into one of two categories: demographic questions or mental health survey questions. During the recode, data subsets representing each of these two categories would be created in order to allow independent investigation within each realm.

Below is a list of a few of the variables from both the demographic and survey question splits, in order to show how the variable names directly matched/relayed their meanings in the original data files:

Example Demographic Variable Names:
* What is your age?
* What is your gender?
* What country do you live in?
* Do you have a family history of mental illness?
* Do you currently have a mental health disorder?

Example Mental Health Survey Variables:
* Would you have been willing to discuss a mental health issue with your previous co-workers?
* Did you feel that your previous employers took mental health as seriously as physical health?
* Was your anonymity protected if you chose to take advantage of mental health or substance abuse treatment resources with previous employers?

### Cleaning the Data
  
* Describe any cleaning you had to do for your data.
  
All of the code required to load and clean our data can be found in our [load_and_clean_data.R](/load_and_clean_data.R) file. Relevant sections of the code have been parsed below to accompany relevant discussions.

DATA CLEANING DISCUSSION, WITH CODE CHUNKS FROM LOAD AND CLEAN
  
  * Also, describe any additional R packages you used outside of those covered in class.
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
  
  
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.